{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b07a981a-cee0-4ed4-9a86-31df48d4e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b0a13f-bf8a-4573-8690-e5fb0d1cd8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the metadata:\n",
      "  _author_id _author _author_L1   _author_age _author_gender  \\\n",
      "0       0601    0601     German  not reported         female   \n",
      "1       0602    0602     German  not reported           male   \n",
      "2       0603    0603     German  not reported           male   \n",
      "3       0604    0604     German  not reported           male   \n",
      "4       0605    0605     German  not reported         female   \n",
      "\n",
      "  _rating_coherence _rating_coherence2 _rating_fair_cefr  \\\n",
      "0                B1                NaN               A2+   \n",
      "1                B1                NaN               A2+   \n",
      "2                B1                NaN                B1   \n",
      "3                B1                NaN                B1   \n",
      "4                B1                NaN                B1   \n",
      "\n",
      "  _rating_fair_cefr_rough _rating_general_linguistic_range  ...  \\\n",
      "0                      A2                               B1  ...   \n",
      "1                      A2                               B1  ...   \n",
      "2                      B1                               B1  ...   \n",
      "3                      B1                               B1  ...   \n",
      "4                      B1                               B1  ...   \n",
      "\n",
      "  syn_dependentClausesWithOutConjToDependentClauses  \\\n",
      "0                                               NaN   \n",
      "1                                               NaN   \n",
      "2                                               NaN   \n",
      "3                                               NaN   \n",
      "4                                               NaN   \n",
      "\n",
      "  syn_interrogativeClausesToDepCWC syn_longestDependency  \\\n",
      "0                              NaN                   NaN   \n",
      "1                              NaN                   NaN   \n",
      "2                              NaN                   NaN   \n",
      "3                              NaN                   NaN   \n",
      "4                              NaN                   NaN   \n",
      "\n",
      "  syn_passiveVoiceToClauseRatio syn_passiveVoiceToSentenceRatio  \\\n",
      "0                           NaN                             NaN   \n",
      "1                           NaN                             NaN   \n",
      "2                           NaN                             NaN   \n",
      "3                           NaN                             NaN   \n",
      "4                           NaN                             NaN   \n",
      "\n",
      "  syn_relativeClausesToDepCWC syn_satzwertigeInfinitiveToDependentClauses  \\\n",
      "0                         NaN                                         NaN   \n",
      "1                         NaN                                         NaN   \n",
      "2                         NaN                                         NaN   \n",
      "3                         NaN                                         NaN   \n",
      "4                         NaN                                         NaN   \n",
      "\n",
      "  syn_sentenceComplexityRatio syn_sentenceCoordinationRatio  \\\n",
      "0                         NaN                           NaN   \n",
      "1                         NaN                           NaN   \n",
      "2                         NaN                           NaN   \n",
      "3                         NaN                           NaN   \n",
      "4                         NaN                           NaN   \n",
      "\n",
      "  syn_verbPhrasesPerTUnit  \n",
      "0                     NaN  \n",
      "1                     NaN  \n",
      "2                     NaN  \n",
      "3                     NaN  \n",
      "4                     NaN  \n",
      "\n",
      "[5 rows x 362 columns]\n",
      "\n",
      "Columns and Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2287 entries, 0 to 2286\n",
      "Columns: 362 entries, _author_id to syn_verbPhrasesPerTUnit\n",
      "dtypes: float64(289), int64(45), object(28)\n",
      "memory usage: 6.3+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konte\\AppData\\Local\\Temp\\ipykernel_13800\\1549374888.py:6: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta = pd.read_csv(metadata_file)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the file\n",
    "metadata_file = 'data/primary_data/merlin-metadata-v1.2/metadata_ratings_indicators.csv'\n",
    "\n",
    "# Try loading as CSV (comma-separated)\n",
    "try:\n",
    "    df_meta = pd.read_csv(metadata_file)\n",
    "except:\n",
    "    # If the file fails to load with the default comma delimiter, try a different one (like tab or semicolon)\n",
    "    # The MERLIN data often uses TSV (tab-separated)\n",
    "    try:\n",
    "        df_meta = pd.read_csv(metadata_file, sep='\\t')\n",
    "        print(\"Successfully loaded metadata using tab separator.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load file. Check the delimiter in the README: {e}\")\n",
    "        # Stop and advise checking the README\n",
    "        exit()\n",
    "\n",
    "# Display the first few rows and column info to confirm successful loading\n",
    "print(\"\\nFirst 5 rows of the metadata:\")\n",
    "print(df_meta.head())\n",
    "print(\"\\nColumns and Data Types:\")\n",
    "print(df_meta.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299e430-b7ae-4553-93ae-06dbae7d3391",
   "metadata": {},
   "source": [
    "## Loaded data and analysed their informations, structure, dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21c4393-a0bb-4df9-8940-c416e270e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total L2 German Learner Texts: 1700\n",
      "Top 5 L1s: \n",
      "_author_L1\n",
      "not reported    284\n",
      "Russian         254\n",
      "Polish          237\n",
      "Other           213\n",
      "Hungarian       178\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming the full DataFrame is named df_meta\n",
    "\n",
    "# 1. Filter out native German speakers (who are in the first 5 rows)\n",
    "df_l2_learners = df_meta[df_meta['_author_L1'] != 'German'].copy()\n",
    "\n",
    "# 2. Convert CEFR to a categorical type for proper sorting (e.g., A1, A2, B1...)\n",
    "cefr_order = ['A1', 'A2', 'A2+', 'B1', 'B1+', 'B2', 'C1', 'C2']\n",
    "df_l2_learners['_rating_fair_cefr'] = pd.Categorical(\n",
    "    df_l2_learners['_rating_fair_cefr'], categories=cefr_order, ordered=True\n",
    ")\n",
    "\n",
    "print(f\"Total L2 German Learner Texts: {len(df_l2_learners)}\")\n",
    "print(f\"Top 5 L1s: \\n{df_l2_learners['_author_L1'].value_counts().head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "023133a5-39c0-4ccb-ae04-ae4e77ac633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CEFR Level Distribution (L2 Texts Only):\n",
      "_rating_fair_cefr\n",
      "A1     0.044665\n",
      "A2     0.225806\n",
      "A2+    0.112283\n",
      "B1     0.275434\n",
      "B1+    0.133375\n",
      "B2     0.178040\n",
      "C1     0.028536\n",
      "C2     0.001861\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of proficiency levels\n",
    "cefr_distribution = df_l2_learners['_rating_fair_cefr'].value_counts(normalize=True).sort_index()\n",
    "print(\"\\nCEFR Level Distribution (L2 Texts Only):\")\n",
    "print(cefr_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6428235-49a3-4715-8321-eaee05e87ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target L1 Counts:\n",
      "English L1 (Alex): 69 texts\n",
      "Chinese L1 (Jia): 10 texts\n"
     ]
    }
   ],
   "source": [
    "# Count texts for Alex's (English) and Jia's (Chinese) L1s\n",
    "l1_counts = df_l2_learners['_author_L1'].value_counts()\n",
    "print(\"\\nTarget L1 Counts:\")\n",
    "print(f\"English L1 (Alex): {l1_counts.get('English', 0)} texts\")\n",
    "print(f\"Chinese L1 (Jia): {l1_counts.get('Chinese', 0)} texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818eff2-4ad7-4fdb-a9fd-8986ce7d82d1",
   "metadata": {},
   "source": [
    "## The number of texts to support my 2nd persona (Jia) is definitely insufficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6f2224-ef48-42ab-9577-8e1b2a070a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CEFR Level Distribution (L2 Texts Only):\n",
      "_rating_fair_cefr\n",
      "A1      72\n",
      "A2     364\n",
      "A2+    181\n",
      "B1     444\n",
      "B1+    215\n",
      "B2     287\n",
      "C1      46\n",
      "C2       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_l2_learners is the DataFrame filtered to exclude native German speakers\n",
    "# We need to see the distribution of proficiency levels.\n",
    "\n",
    "# 1. Filter out native German speakers (who were in the first 5 rows)\n",
    "df_l2_learners = df_meta[df_meta['_author_L1'] != 'German'].copy()\n",
    "\n",
    "# 2. Convert CEFR to a categorical type for proper sorting (e.g., A1, A2, B1...)\n",
    "cefr_order = ['A1', 'A2', 'A2+', 'B1', 'B1+', 'B2', 'C1', 'C2']\n",
    "df_l2_learners['_rating_fair_cefr'] = pd.Categorical(\n",
    "    df_l2_learners['_rating_fair_cefr'], categories=cefr_order, ordered=True\n",
    ")\n",
    "\n",
    "# Distribution of proficiency levels\n",
    "cefr_distribution = df_l2_learners['_rating_fair_cefr'].value_counts(normalize=False).sort_index()\n",
    "\n",
    "print(\"\\nCEFR Level Distribution (L2 Texts Only):\")\n",
    "print(cefr_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14db5061-385d-4eda-95fa-e61202fe4e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified Error Rate Columns in Metadata (If any):\n",
      "['ind_errorfree_sentence', 'ind_errorfree_sentence_C_Con_accur', 'ind_errorfree_sentence_G', 'ind_errorfree_sentence_G_Art', 'ind_errorfree_sentence_G_Clit', 'ind_errorfree_sentence_G_Conj', 'ind_errorfree_sentence_G_Inflect_Inexist', 'ind_errorfree_sentence_G_Morphol_Wrong', 'ind_errorfree_sentence_G_Neg', 'ind_errorfree_sentence_G_Prep', 'ind_errorfree_sentence_G_Refl', 'ind_errorfree_sentence_G_Valency', 'ind_errorfree_sentence_G_Verb', 'ind_errorfree_sentence_G_Verb_compl', 'ind_errorfree_sentence_G_Verb_main', 'ind_errorfree_sentence_G_Wo', 'ind_errorfree_sentence_O', 'ind_errorfree_sentence_O_Apostr', 'ind_errorfree_sentence_O_Graph', 'ind_errorfree_sentence_O_Punct', 'ind_errorfree_sentence_O_Wordbd', 'ind_errorfree_sentence_S_Form', 'ind_errorfree_sentence_S_Var', 'ind_errorfree_sentence_V', 'ind_errorfree_sentence_V_Wordform', 'ind_errorfree_sentence_V_form_word_fs_nonexist', 'ind_errorfree_sentence_V_semconn_at_word_fs', 'ind_errorfree_sentence_V_semdenot_word_fs', 'ind_errorfree_sentence_V_semimprec', 'ind_errorfree_token', 'ind_errorfree_token_C_Con_accur', 'ind_errorfree_token_G', 'ind_errorfree_token_G_Art', 'ind_errorfree_token_G_Clit', 'ind_errorfree_token_G_Conj', 'ind_errorfree_token_G_Inflect_Inexist', 'ind_errorfree_token_G_Morphol_Wrong', 'ind_errorfree_token_G_Neg', 'ind_errorfree_token_G_Prep', 'ind_errorfree_token_G_Refl', 'ind_errorfree_token_G_Valency', 'ind_errorfree_token_G_Verb', 'ind_errorfree_token_G_Verb_compl', 'ind_errorfree_token_G_Verb_main', 'ind_errorfree_token_G_Wo', 'ind_errorfree_token_O', 'ind_errorfree_token_O_Apostr', 'ind_errorfree_token_O_Graph', 'ind_errorfree_token_O_Punct', 'ind_errorfree_token_O_Wordbd', 'ind_errorfree_token_S_Form', 'ind_errorfree_token_S_Var', 'ind_errorfree_token_V', 'ind_errorfree_token_V_Wordform', 'ind_errorfree_token_V_form_word_fs_nonexist', 'ind_errorfree_token_V_semconn_at_word_fs', 'ind_errorfree_token_V_semdenot_word_fs', 'ind_errorfree_token_V_semimprec']\n"
     ]
    }
   ],
   "source": [
    "# Extracting columns that relate to linguistic complexity and proficiency\n",
    "key_columns = ['_author_L1', '_author_gender', '_rating_fair_cefr', '_task_id']\n",
    "\n",
    "# We need to find columns that quantify error rates.\n",
    "# Look for columns containing \"error\" or \"incorrect\" if they exist in the metadata.\n",
    "error_rate_columns = [col for col in df_l2_learners.columns if 'error' in col.lower() or 'incorrect' in col.lower()]\n",
    "\n",
    "# We'll also select a few representative linguistic metrics (the NaN values suggest these columns need cleaning)\n",
    "linguistic_metrics = [\n",
    "    'lex_lexicalDensity', # How rich the vocabulary is\n",
    "    'syn_sentenceComplexityRatio', # How complex the sentences are\n",
    "    'syn_passiveVoiceToSentenceRatio' # Use of passive voice (more advanced structure)\n",
    "]\n",
    "\n",
    "print(\"\\nIdentified Error Rate Columns in Metadata (If any):\")\n",
    "print(error_rate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6809412-e1df-4752-bd19-68c997759656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Error Rate (1 - Error Free Rate) by CEFR Level:\n",
      "                   ind_errorfree_sentence_G  ind_errorfree_sentence_G_Art  \\\n",
      "_rating_fair_cefr                                                           \n",
      "A1                                    0.239                         0.148   \n",
      "A2                                    0.152                         0.081   \n",
      "A2+                                   0.104                         0.053   \n",
      "B1                                    0.072                         0.047   \n",
      "B1+                                   0.052                         0.028   \n",
      "B2                                    0.058                         0.034   \n",
      "C1                                    0.021                         0.010   \n",
      "C2                                    0.000                         0.000   \n",
      "\n",
      "                   ind_errorfree_sentence_G_Wo  ind_errorfree_sentence_G_Verb  \\\n",
      "_rating_fair_cefr                                                               \n",
      "A1                                       0.049                          0.115   \n",
      "A2                                       0.072                          0.071   \n",
      "A2+                                      0.061                          0.055   \n",
      "B1                                       0.040                          0.044   \n",
      "B1+                                      0.030                          0.033   \n",
      "B2                                       0.036                          0.030   \n",
      "C1                                       0.014                          0.008   \n",
      "C2                                       0.000                          0.000   \n",
      "\n",
      "                   ind_errorfree_sentence_G_Prep  \n",
      "_rating_fair_cefr                                 \n",
      "A1                                         0.096  \n",
      "A2                                         0.095  \n",
      "A2+                                        0.066  \n",
      "B1                                         0.051  \n",
      "B1+                                        0.039  \n",
      "B2                                         0.035  \n",
      "C1                                         0.004  \n",
      "C2                                         0.000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konte\\AppData\\Local\\Temp\\ipykernel_13800\\63388433.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  error_free_rates = df_l2_learners[error_cols].groupby('_rating_fair_cefr').mean()\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_l2_learners is your DataFrame filtered for L2 texts with the CEFR column set as categorical.\n",
    "\n",
    "error_cols = [\n",
    "    '_rating_fair_cefr', # Key for grouping\n",
    "    'ind_errorfree_sentence_G',\n",
    "    'ind_errorfree_sentence_G_Art',\n",
    "    'ind_errorfree_sentence_G_Wo',\n",
    "    'ind_errorfree_sentence_G_Verb',\n",
    "    'ind_errorfree_sentence_G_Prep'\n",
    "]\n",
    "\n",
    "# 1. Select relevant columns and group by CEFR level, calculating the mean error-free rate\n",
    "error_free_rates = df_l2_learners[error_cols].groupby('_rating_fair_cefr').mean()\n",
    "\n",
    "# 2. Convert error-free rate (0 to 1) to error rate (0 to 1) for easier interpretation\n",
    "# A higher number means a higher error rate.\n",
    "average_error_rates = 1 - error_free_rates\n",
    "\n",
    "# 3. Round and display the results\n",
    "print(\"\\nAverage Error Rate (1 - Error Free Rate) by CEFR Level:\")\n",
    "print(average_error_rates.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8bfff-dbb5-4dbb-81d8-8aa92c59a977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
